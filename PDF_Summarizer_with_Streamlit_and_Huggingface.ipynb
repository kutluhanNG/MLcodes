{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrg54TerhwICDXuUg2YJfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kutluhanNG/MLcodes/blob/main/PDF_Summarizer_with_Streamlit_and_Huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ya1fJvI9K9t"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "AmNZpW3k9PHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st #Streamlit library for building interactive web apps.\n",
        "import PyPDF2 #PyPDF2 for reading and extracting text from PDF files.\n",
        "import re #Importing the built-in Python regular expressions, we will be using it for splitting text into sentences.\n",
        "from transformers import pipeline\n",
        "\n",
        "@st.cache_resource # Cache the summarizer so it is loaded only once.\n",
        "def load_summarizer():\n",
        "    # Using an open-source summarization model from Hugging Face. You can change the model if you want.\n",
        "    summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
        "    return summarizer\n",
        "\n",
        "def split_text(text, max_length=1000): #Function to split the sentences and put them into chunks.\n",
        "\n",
        "    sentences = re.split(r'(?<=[.!?]) +', text) #This line splits the text into sentences.\n",
        "    chunks = [] #We initialize an empty chunk list to add our sentences.\n",
        "    current_chunk = \"\" #We initialize a current chunk string to add to chunk list.\n",
        "    for sentence in sentences: #Iterating over the splitted sentences one by one.\n",
        "        if len(current_chunk) + len(sentence) <= max_length: #If the current chunks character size plus the current sentences size do not exceed the chunk size, we add that sentence to current chunk.\n",
        "            current_chunk += sentence + \" \"\n",
        "        else: #If adding the current sentence to current chunks exceeds the chunk's character size limit, we add the current chunk to the list of chunks and continue our process with brand new current chunk and add current sentence there.\n",
        "            chunks.append(current_chunk.strip())\n",
        "            current_chunk = sentence + \" \"\n",
        "    if current_chunk: #If there is any remaining text in the current chunk after process is complete, we add it to the chunk list too.\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "def extract_text_from_pdf(pdf_file): #Function to extracting text from uploaded PDF.\n",
        "\n",
        "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "    text = \"\"\n",
        "    for page in pdf_reader.pages:\n",
        "        page_text = page.extract_text() or \"\"\n",
        "        text += page_text\n",
        "    return text\n",
        "\n",
        "def main():\n",
        "    st.title(\"PDF Summarizer\") # Sets the title of the web application.\n",
        "    st.write(\"Upload a PDF and get a summary of its contents!\") # Writes a short description.\n",
        "\n",
        "    # File uploader widget accepts only PDF files.\n",
        "    uploaded_file = st.file_uploader(\"Choose a PDF file\", type=\"pdf\") # Creates a file uploader widget that only accepts PDF. We will store the uploaded file in the variable uploaded_variable.\n",
        "\n",
        "    if uploaded_file is not None: # Checks if any file is uploaded.\n",
        "        with st.spinner(\"Extracting text from PDF...\"): #Displays a spinner with the message “Extracting text from PDF...” while the extraction is in progress.\n",
        "            text = extract_text_from_pdf(uploaded_file)  # Calls the function that we built above to extract the text from the uploaded PDF file.\n",
        "        st.success(\"Text extracted!\")\n",
        "        st.write(f\"Extracted {len(text)} characters.\")\n",
        "\n",
        "        if st.button(\"Summarize\"): # Creates a button labeled \"Summarize\".\n",
        "            summarizer = load_summarizer() # Calls the summarizing function that we built above.\n",
        "            with st.spinner(\"Summarizing text...\"): # Displays a spinner with the message.\n",
        "                if len(text) > 1000: # Checks if the extracted text is longer than 1000 characters.\n",
        "                    chunks = split_text(text, max_length=1000) # Splits the text into chunks.\n",
        "                    summary_chunks = [] # Initializes an empty list to store every individual chunk's summary.\n",
        "                    for chunk in chunks:\n",
        "                        summary = summarizer(chunk, max_length=130, min_length=30, do_sample=False) # Summarizes each chunk.\n",
        "                        summary_chunks.append(summary[0]['summary_text']) # Appends the generated summary from the first result.\n",
        "                    final_summary = \" \".join(summary_chunks) # Joins all the individual summaries.\n",
        "                else: #If the text is not too longi the summarizer runs on the entire text at once.\n",
        "                    summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "                    final_summary = summary[0]['summary_text']\n",
        "\n",
        "            st.write(\"### Summary\")\n",
        "            st.write(final_summary)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "CzSyAgH69PYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py"
      ],
      "metadata": {
        "id": "k2aT0SNY9V0W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}